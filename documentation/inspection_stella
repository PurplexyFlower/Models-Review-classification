# --- DEBUGGING SNIPPET: How to find layer names ---
from transformers import AutoModel, AutoConfig

# Load the configuration and disable memory efficient attention
config = AutoConfig.from_pretrained("NovaSearch/stella_en_400M_v5", trust_remote_code=True)
config.use_memory_efficient_attention = False
config.unpad_inputs = False

# Load the base model without any quantization to quickly inspect it
model_to_inspect = AutoModel.from_pretrained(
    "NovaSearch/stella_en_400M_v5", 
    config=config,
    trust_remote_code=True
)

print("üîç All named modules in the Stella model:")
print("=" * 80)

# Print all the named modules in the model
linear_layers = []
attention_layers = []

for name, module in model_to_inspect.named_modules():
    module_type = type(module).__name__
    
    # Print first 50 modules to see the structure
    if len(linear_layers) + len(attention_layers) < 50:
        print(f"{name:<60} -> {module_type}")
    
    # Collect Linear layers
    if 'Linear' in module_type:
        linear_layers.append(name)
        
        # Check if it's attention-related
        if any(keyword in name.lower() for keyword in ['attn', 'attention', 'query', 'key', 'value', 'qkv', 'dense']):
            attention_layers.append(name)

print(f"\nüìä Summary:")
print(f"Total Linear layers found: {len(linear_layers)}")
print(f"Attention-related layers: {len(attention_layers)}")

print(f"\nüéØ First 10 Linear layers:")
for i, layer in enumerate(linear_layers[:10]):
    print(f"   {i+1:2d}. {layer}")

print(f"\nüéØ Attention-related layers:")
for layer in attention_layers[:20]:  # Show first 20
    print(f"   - {layer}")

if len(attention_layers) > 20:
    print(f"   ... and {len(attention_layers) - 20} more")

# Extract target module patterns
print(f"\nüìù Target module patterns:")
unique_endings = set()
for layer in attention_layers:
    ending = layer.split('.')[-1]
    unique_endings.add(ending)

print(f"Unique attention layer endings: {sorted(list(unique_endings))}")

# Recommended target modules for LoRA
recommended = list(unique_endings)[:3]  # Take first 3 most common
print(f"\n‚úÖ Recommended target_modules for LoRA: {recommended}")

# Clean up
del model_to_inspect